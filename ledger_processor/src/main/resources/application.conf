akka {
  actor {
    provider = "cluster"
    allow-java-serialization = false
  }
  remote.artery.bind {
    hostname = "0.0.0.0"
    port = 25520
  }

  cluster {
    min-nr-of-members = 1
    allow-weakly-up-members = off
    # Recommended configuration by Akka Cluster Bootstrap
    # https://doc.akka.io/docs/akka-management/current/bootstrap/index.html#recommended-configuration
    # Wait for 60s before shutting down a node that can't join. This should allow us time to collect the logs
    shutdown-after-unsuccessful-join-seed-nodes = 60s
  }
  management {
    http {
      route-providers-read-only = true
      bind-hostname = "0.0.0.0"
      bind-port = 8558
    }
    health-checks {
      check-timeout = 5s
      readiness-checks {
        # Health check to see if this service is ready to accept traffic.
        cluster-membership = "akka.management.cluster.scaladsl.ClusterMembershipCheck"
      }
      liveness-checks {
        # Health check to see if this service started up properly.
      }
    }
    cluster {
      # Ready health check returns 200 when cluster membership is in the following states.
      # Intended to be used to indicate this node is ready for user traffic so Up/WeaklyUp
      # Valid values: "Joining", "WeaklyUp", "Up", "Leaving", "Exiting", "Down", "Removed"

      # 'WeaklyUp' has been removed because we do cluster sharding.
      # All members must be fully aware of each other with no exception before a new joiner is considered healthy
      health-check.ready-states = ["Up"]
      bootstrap {
        new-cluster-enabled = on
        contact-point-discovery: ${ledger-settings.cluster-discovery}
      }
    }
  }
}

akka.actor.serialization-bindings {
  "io.openledger.LedgerSerializable" = jackson-cbor
  "io.openledger.events.AccountEvent" = jackson-cbor
  "io.openledger.events.TransactionEvent" = jackson-cbor
}

akka.kafka.producer {
  # Set a service name for use with Akka Discovery
  # https://doc.akka.io/docs/alpakka-kafka/current/discovery.html
  service-name = ""

  # Fully qualified config path which holds the dispatcher configuration
  # to be used by the producer stages. Some blocking may occur.
  # When this value is empty, the dispatcher configured for the stream
  # will be used.
  use-dispatcher = "akka.kafka.default-dispatcher"

  # Properties defined by org.apache.kafka.clients.producer.ProducerConfig
  # can be defined in this configuration section.
  kafka-clients: ${ledger-settings.kafka.outgoing.client}
}

akka.kafka.consumer {
  # Set a service name for use with Akka Discovery
  # https://doc.akka.io/docs/alpakka-kafka/current/discovery.html
  service-name = ""

  # Fully qualified config path which holds the dispatcher configuration
  # to be used by the KafkaConsumerActor. Some blocking may occur.
  use-dispatcher = "akka.kafka.default-dispatcher"

  # Properties defined by org.apache.kafka.clients.consumer.ConsumerConfig
  # can be defined in this configuration section.
  kafka-clients: ${ledger-settings.kafka.incoming.client}

}

akka.kafka.committer {
  # Maximum interval between commits
  max-interval = 1s
}

akka.cluster.sharding {

  # Set this to a time duration to have sharding passivate entities when they have not
  # received any message in this length of time. Set to 'off' to disable.
  # It is always disabled if `remember-entities` is enabled.
  passivate-idle-entity-after = 30s

  # The id of the dispatcher to use for ClusterSharding actors.
  # If specified you need to define the settings of the actual dispatcher.
  # This dispatcher for the entity actors is defined by the user provided
  # Props, i.e. this dispatcher is not used for the entity actors.
  use-dispatcher = "akka.actor.internal-dispatcher"

  # Config path of the lease that each shard must acquire before starting entity actors
  # default is no lease
  # A lease can also be used for the singleton coordinator by settings it in the coordinator-singleton properties
  use-lease = ""

  # The interval between retries for acquiring the lease
  lease-retry-interval = 5s

  # Number of shards used by the default HashCodeMessageExtractor
  # when no other message extractor is defined. This value must be
  # the same for all nodes in the cluster and that is verified by
  # configuration check when joining. Changing the value requires
  # stopping all nodes in the cluster.
  number-of-shards = 1000
}

akka {
  persistence {
    journal {
      plugin = "jdbc-journal"
      auto-start-journals = ["jdbc-journal"]
    }
    snapshot-store {
      plugin = "jdbc-snapshot-store"
      auto-start-snapshot-stores = ["jdbc-snapshot-store"]
    }
  }
}

akka-persistence-jdbc {
  shared-databases {
    slick {
      profile = "slick.jdbc.PostgresProfile$"
      db {
        url = "jdbc:postgresql://"${akka-persistence-jdbc.shared-databases.slick.db.host}":"${akka-persistence-jdbc.shared-databases.slick.db.port}"/"${akka-persistence-jdbc.shared-databases.slick.db.name}"?reWriteBatchedInserts=true&currentSchema="${akka-persistence-jdbc.shared-databases.slick.db.schema}
        host = ${ledger-settings.database.host}
        port = ${ledger-settings.database.port}
        name = ${ledger-settings.database.name}
        schema = ${ledger-settings.database.schema}
        user = ${ledger-settings.database.username}
        password = ${ledger-settings.database.password}
        driver = "org.postgresql.Driver"
        numThreads = ${ledger-settings.database.number-of-connections}
        maxConnections = ${akka-persistence-jdbc.shared-databases.slick.db.numThreads}
        minConnections = ${akka-persistence-jdbc.shared-databases.slick.db.numThreads}
      }
    }
  }
}

jdbc-journal {
  use-shared-db = "slick"
}

jdbc-snapshot-store {
  use-shared-db = "slick"
}

jdbc-read-journal {
  use-shared-db = "slick"
}

ledger-settings {
  processor {
    timeout = 30s
  }

  cluster-discovery {
    discovery-method = akka-dns
    effective-name = "openledger"
  }

  database {
    host = "postgres"
    port = 5432
    name = "openledger_db"
    schema = "public"
    username = "openledger_user"
    password = "openledger_password"
    number-of-connections = 10
  }
  kafka {
    incoming {
      topics = ["openledger_incoming"]
      message-per-second = 10
      client {
        enable.auto.commit = false
        bootstrap.servers = "kafka:9092"
        group.id = "openledger_processor"
        //        security.protocol = SSL
        //        ssl.truststore.location = /trust-stores/kafka.client.truststore.jks
      }
    }
    outgoing {
      topic = "openledger_outgoing"
      buffer-size = 100
      client {
        bootstrap.servers = "kafka:9092"
        //        security.protocol = SSL
        //        ssl.truststore.location = /trust-stores/kafka.client.truststore.jks
      }
    }
  }
}